{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e88dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Markdown\n",
    "# # Feature Engineering and Model Prototyping\n",
    "\n",
    "# This notebook serves as a workspace for:\n",
    "# 1.  Refining feature engineering ideas beyond the basic steps.\n",
    "# 2.  Experimenting with data transformation techniques (scaling, encoding).\n",
    "# 3.  Testing different strategies for handling class imbalance.\n",
    "# 4.  Prototyping and evaluating initial machine learning models (Logistic Regression, LightGBM)\n",
    "# 5.  Exploring hyperparameter tuning with GridSearchCV.\n",
    "\n",
    "# The goal here is to iterate quickly and gain insights that inform the final, formalized code in the `src/` directory.\n",
    "\n",
    "# Cell 2: Code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    f1_score, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    average_precision_score, precision_recall_curve, auc, make_scorer\n",
    ")\n",
    "from collections import Counter\n",
    "import joblib # For saving/loading preprocessors or pipelines\n",
    "import sys\n",
    "\n",
    "# Set display options for better viewing\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Define paths\n",
    "PROCESSED_DATA_PATH = '../data/processed/' # Relative path from notebooks/\n",
    "MODELS_PATH = '../models/'\n",
    "REPORTS_PATH = '../reports/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "\n",
    "print(\"--- Starting Feature Engineering & Model Prototyping Notebook ---\")\n",
    "\n",
    "# Cell 3: Markdown\n",
    "# ## 1. Load Engineered Data\n",
    "\n",
    "# We'll load the data that has already undergone basic cleaning and initial feature engineering from the previous `src/` scripts.\n",
    "\n",
    "# Cell 4: Code\n",
    "print(\"Loading engineered data...\")\n",
    "try:\n",
    "    fraud_data_df = pd.read_csv(os.path.join(PROCESSED_DATA_PATH, 'fraud_data_engineered.csv'))\n",
    "    creditcard_df = pd.read_csv(os.path.join(PROCESSED_DATA_PATH, 'creditcard_engineered.csv'))\n",
    "    print(\"Engineered data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading engineered file: {e}. Please ensure 'src/feature_engineering.py' has been run successfully.\")\n",
    "\n",
    "print(\"\\nE-commerce Data Head:\")\n",
    "print(fraud_data_df.head())\n",
    "print(\"\\nBank Data Head:\")\n",
    "print(creditcard_df.head())\n",
    "\n",
    "# Cell 5: Markdown\n",
    "# ## 2. Data Preparation for Modeling\n",
    "\n",
    "# This involves separating features (X) from the target (y) and performing a train-test split. We will also define our preprocessing steps.\n",
    "\n",
    "# Cell 6: Code\n",
    "# --- E-commerce Data Preparation ---\n",
    "print(\"\\n--- Preparing E-commerce Data for Modeling ---\")\n",
    "X_ecommerce = fraud_data_df.drop(columns=['class', 'user_id', 'device_id', 'ip_address']) # Drop target and identifiers\n",
    "y_ecommerce = fraud_data_df['class']\n",
    "\n",
    "X_train_eco, X_test_eco, y_train_eco, y_test_eco = train_test_split(\n",
    "    X_ecommerce, y_ecommerce, test_size=0.2, random_state=42, stratify=y_ecommerce\n",
    ")\n",
    "\n",
    "print(\"E-commerce Data Class distribution (train/test):\")\n",
    "print(f\"Train: {Counter(y_train_eco)}\")\n",
    "print(f\"Test: {Counter(y_test_eco)}\")\n",
    "\n",
    "# Define preprocessing steps for E-commerce data\n",
    "numerical_features_eco = X_ecommerce.select_dtypes(include=np.number).columns\n",
    "categorical_features_eco = X_ecommerce.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "preprocessor_eco = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features_eco),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_eco)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# --- Bank Data Preparation ---\n",
    "print(\"\\n--- Preparing Bank Data for Modeling ---\")\n",
    "X_bank = creditcard_df.drop(columns=['Class']) # Drop target\n",
    "y_bank = creditcard_df['Class']\n",
    "\n",
    "X_train_bank, X_test_bank, y_bank_train, y_bank_test = train_test_split(\n",
    "    X_bank, y_bank, test_size=0.2, random_state=42, stratify=y_bank\n",
    ")\n",
    "\n",
    "print(\"Bank Data Class distribution (train/test):\")\n",
    "print(f\"Train: {Counter(y_bank_train)}\")\n",
    "print(f\"Test: {Counter(y_bank_test)}\")\n",
    "\n",
    "# Define preprocessing steps for Bank data (all features are numerical except target)\n",
    "numerical_features_bank = X_bank.select_dtypes(include=np.number).columns\n",
    "categorical_features_bank = X_bank.select_dtypes(include=['object', 'bool']).columns # Should be empty\n",
    "\n",
    "preprocessor_bank = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features_bank),\n",
    "        # No categorical features for bank data, but keep for consistency\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_bank) \n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Cell 7: Markdown\n",
    "# ## 3. Model Prototyping and Evaluation\n",
    "\n",
    "# We will prototype Logistic Regression and LightGBM models. This section will also demonstrate how to use `imblearn.pipeline` to integrate sampling techniques like SMOTE.\n",
    "\n",
    "# **Evaluation Function (same as in `src/model_training.py` for consistency):**\n",
    "\n",
    "# Cell 8: Code\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name, dataset_name):\n",
    "    \"\"\"Evaluates a classification model using F1-score, AUC-PR, and Confusion Matrix.\"\"\"\n",
    "    print(f\"\\n--- {model_name} Performance on {dataset_name} ---\")\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    pr_auc = average_precision_score(y_true, y_prob)\n",
    "    print(f\"AUC-PR: {pr_auc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    cmp.plot(ax=ax)\n",
    "    ax.set_title(f'Confusion Matrix - {model_name} on {dataset_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show() # In notebook, show directly\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    pr_curve_auc = auc(recall, precision)\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(recall, precision, label=f'{model_name} (AUC-PR = {pr_curve_auc:.4f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - {model_name} on {dataset_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show() # In notebook, show directly\n",
    "\n",
    "    return {'f1_score': f1, 'auc_pr': pr_auc, 'confusion_matrix': cm}\n",
    "\n",
    "# Cell 9: Markdown\n",
    "# ### 3.1. E-commerce Data Models\n",
    "\n",
    "# Cell 10: Code\n",
    "print(\"\\n--- Training Logistic Regression for E-commerce Data ---\")\n",
    "lr_pipeline_eco = ImbPipeline(steps=[('preprocessor', preprocessor_eco),\n",
    "                                    ('sampler', SMOTE(random_state=42)),\n",
    "                                    ('classifier', LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced', max_iter=1000))])\n",
    "\n",
    "lr_pipeline_eco.fit(X_train_eco, y_train_eco)\n",
    "\n",
    "y_pred_lr_eco = lr_pipeline_eco.predict(X_test_eco)\n",
    "y_prob_lr_eco = lr_pipeline_eco.predict_proba(X_test_eco)[:, 1]\n",
    "\n",
    "evaluate_model(y_test_eco, y_pred_lr_eco, y_prob_lr_eco, 'Logistic Regression', 'E-commerce Data')\n",
    "\n",
    "print(\"\\n--- Training LightGBM for E-commerce Data ---\")\n",
    "lgbm_pipeline_eco = ImbPipeline(steps=[('preprocessor', preprocessor_eco),\n",
    "                                       ('sampler', SMOTE(random_state=42)),\n",
    "                                       ('classifier', lgb.LGBMClassifier(random_state=42, objective='binary', is_unbalance=True))])\n",
    "\n",
    "lgbm_pipeline_eco.fit(X_train_eco, y_train_eco)\n",
    "\n",
    "y_pred_lgbm_eco = lgbm_pipeline_eco.predict(X_test_eco)\n",
    "y_prob_lgbm_eco = lgbm_pipeline_eco.predict_proba(X_test_eco)[:, 1]\n",
    "\n",
    "evaluate_model(y_test_eco, y_pred_lgbm_eco, y_prob_lgbm_eco, 'LightGBM', 'E-commerce Data')\n",
    "\n",
    "# Cell 11: Markdown\n",
    "# ### 3.2. Bank Data Models\n",
    "\n",
    "# Cell 12: Code\n",
    "print(\"\\n--- Training Logistic Regression for Bank Data ---\")\n",
    "lr_pipeline_bank = ImbPipeline(steps=[('preprocessor', preprocessor_bank),\n",
    "                                    ('sampler', SMOTE(random_state=42)),\n",
    "                                    ('classifier', LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced', max_iter=1000))])\n",
    "\n",
    "lr_pipeline_bank.fit(X_train_bank, y_bank_train)\n",
    "\n",
    "y_pred_lr_bank = lr_pipeline_bank.predict(X_test_bank)\n",
    "y_prob_lr_bank = lr_pipeline_bank.predict_proba(X_test_bank)[:, 1]\n",
    "\n",
    "evaluate_model(y_bank_test, y_pred_lr_bank, y_prob_lr_bank, 'Logistic Regression', 'Bank Data')\n",
    "\n",
    "\n",
    "print(\"\\n--- Training LightGBM for Bank Data ---\")\n",
    "lgbm_pipeline_bank = ImbPipeline(steps=[('preprocessor', preprocessor_bank),\n",
    "                                       ('sampler', SMOTE(random_state=42)),\n",
    "                                       ('classifier', lgb.LGBMClassifier(random_state=42, objective='binary', is_unbalance=True))])\n",
    "\n",
    "lgbm_pipeline_bank.fit(X_train_bank, y_bank_train)\n",
    "\n",
    "y_pred_lgbm_bank = lgbm_pipeline_bank.predict(X_test_bank)\n",
    "y_prob_lgbm_bank = lgbm_pipeline_bank.predict_proba(X_test_bank)[:, 1]\n",
    "\n",
    "evaluate_model(y_bank_test, y_pred_lgbm_bank, y_prob_lgbm_bank, 'LightGBM', 'Bank Data')\n",
    "\n",
    "# Cell 13: Markdown\n",
    "# ## 4. Hyperparameter Tuning Experiment (Example using GridSearchCV for LightGBM)\n",
    "\n",
    "# This section demonstrates how you might experiment with hyperparameter tuning. Note that full-scale hyperparameter tuning can be computationally expensive.\n",
    "\n",
    "# **Note:** Running this section might take significant time depending on your hardware and the size of the parameter grid. You might want to run this on a smaller subset of data or with fewer cross-validation folds for quicker prototyping.\n",
    "\n",
    "# Cell 14: Code\n",
    "print(\"\\n--- Hyperparameter Tuning Example: LightGBM for E-commerce Data ---\")\n",
    "\n",
    "# Define a scoring metric for GridSearchCV (AUC-PR is excellent for imbalanced data)\n",
    "scorer = make_scorer(average_precision_score, needs_proba=True, pos_label=1)\n",
    "\n",
    "# Define the pipeline for GridSearch (with SMOTE as part of the pipeline steps)\n",
    "lgbm_pipeline_gs = ImbPipeline(steps=[('preprocessor', preprocessor_eco),\n",
    "                                       ('sampler', SMOTE(random_state=42)),\n",
    "                                       ('classifier', lgb.LGBMClassifier(random_state=42, objective='binary'))])\n",
    "\n",
    "# Define a smaller parameter grid for quick testing in a notebook\n",
    "param_grid_lgbm = {\n",
    "    'classifier__n_estimators': [100, 200], # Number of boosting rounds\n",
    "    'classifier__learning_rate': [0.05, 0.1], # Step size shrinkage\n",
    "    'classifier__num_leaves': [20, 31], # Max number of leaves in one tree\n",
    "}\n",
    "\n",
    "grid_search_lgbm = GridSearchCV(lgbm_pipeline_gs, param_grid_lgbm, cv=3, scoring=scorer, verbose=2, n_jobs=-1)\n",
    "\n",
    "print(\"Fitting GridSearchCV (this may take some time)...\")\n",
    "grid_search_lgbm.fit(X_train_eco, y_train_eco)\n",
    "\n",
    "print(\"\\nBest parameters for LightGBM (E-commerce):\", grid_search_lgbm.best_params_)\n",
    "print(\"Best AUC-PR score for LightGBM (E-commerce) from GridSearchCV:\", grid_search_lgbm.best_score_)\n",
    "\n",
    "# Evaluate the best model found by GridSearchCV on the test set\n",
    "best_lgbm_eco_tuned = grid_search_lgbm.best_estimator_\n",
    "y_pred_lgbm_eco_tuned = best_lgbm_eco_tuned.predict(X_test_eco)\n",
    "y_prob_lgbm_eco_tuned = best_lgbm_eco_tuned.predict_proba(X_test_eco)[:, 1]\n",
    "\n",
    "evaluate_model(y_test_eco, y_pred_lgbm_eco_tuned, y_prob_lgbm_eco_tuned, 'Tuned LightGBM', 'E-commerce Data')\n",
    "\n",
    "# Cell 15: Markdown\n",
    "# ## 5. Conclusion and Transition to Formal Scripts\n",
    "\n",
    "# This notebook demonstrates the iterative process of feature engineering and model prototyping. The insights gained here (e.g., effective features, promising model types, initial hyperparameter ranges, choice of imbalance handling) are directly translated into the more structured and reproducible Python scripts in the `src/` directory.\n",
    "\n",
    "# The `src/model_training.py` script will use these findings to train the final models. The `src/model_explainability.py` script will then interpret the best-performing models using SHAP."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
